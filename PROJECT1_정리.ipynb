{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 소개\n",
    "* 조명 - 치즈케이크\n",
    "* 프로젝트명 - \n",
    "* 분석목적 - 최근 유행하는 치즈케이크 집의 분포를 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 조원소개와 역할 (사진포함)\n",
    "* 김다영\n",
    "* 김민기\n",
    "* 서준영\n",
    "* 이수진"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 데이터 출처와 전처리 전의 데이터 구조 (테이블구조로 샘플수와 속성 설명 포함)\n",
    "## (1) 데이터 수집 방법 : 크롤링\n",
    "* 데이터 출처 : 인스타그램\n",
    "인스타그램에서 #치즈케이크 해시태그로 검색하여 최근 게시물 데이터를 확보했다.\n",
    "\n",
    "목표 샘플수는 10000개를 목표로 했으나, 인스타그램의 검색량 제한으로 중간에 멈췄다.\n",
    "\n",
    "따라서 크롤링 과정을 2단계로 나누어 네 명이서 크롤링을 분담하였다.\n",
    "\n",
    "특징: 위치 정보를 입력하지 않는 글은 저장되지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from urllib.parse import quote\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "#사전정보 입력\n",
    "handle = '' #인스타그램 아이디\n",
    "pwd = ''  #인스타그램 비밀번호\n",
    "\n",
    "keyword= '치즈케이크'   #검색할 키워드\n",
    "num_of_pages = 800 #몇 번 스크롤 할 건지; e.g. 200 --> 1730개 게시글 긁어짐\n",
    "driver_dir = 'c:/Temp/chromedriver.exe'    #크롬드라이버 경로\n",
    "k = 1 # k는 1~4로 각각 맡음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1단계 : 검색 페이지에서 글 URL 가져오기\n",
    "def InstagramUrlFromKeyword (browser,keyword,num_of_pagedowns):\n",
    "    keyword_url_encode=quote(keyword)\n",
    "    url='https://www.instagram.com/explore/tags/'+keyword+'/?hl=ko'\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "    login = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/span/a[1]/button')\n",
    "    login.click()\n",
    "    time.sleep(3)\n",
    "    user_id = browser.find_element_by_class_name('_2hvTZ.pexuQ.zyHYP')\n",
    "    pw = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[3]/div/label/input')\n",
    "    user_id.send_keys(handle)\n",
    "    pw.send_keys(pwd)\n",
    "    button = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/button')\n",
    "    button.click()\n",
    "    time.sleep(3)\n",
    "    arr_href=[]\n",
    "    body=browser.find_element_by_tag_name('body')\n",
    "    for i in range(num_of_pagedowns):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "        post=browser.find_elements_by_class_name('v1Nh3')\n",
    "        for j in post:\n",
    "            href_str=j.find_element_by_css_selector('a').get_attribute('href')\n",
    "            arr_href.append(href_str)\n",
    "    return set(arr_href)    \n",
    "\n",
    "char = r'#[\\d\\w]+'\n",
    "char2 = re.compile('[^ 0-9a-zA-Zㄱ-ㅣ가-힣!#?]')\n",
    "\n",
    "#2단계 : URL 정보를 4명분으로 나누기\n",
    "arr = list(arr)\n",
    "text1 = arr[:threshold]\n",
    "text2 = arr[threshold: 2*threshold]\n",
    "text3 = arr[2*threshold: 3*threshold]\n",
    "text4 = arr[3*threshold:]\n",
    "texts = [text1, text2, text3, text4]\n",
    "\n",
    "for k in range(len(texts)):\n",
    "    with open('url_part' + str(k+1) + '.txt', 'w') as f:\n",
    "        for url in texts[k]:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "\n",
    "#3단계 : 글 URL에서 필요한 데이터 수집\n",
    "def IdHashTagFromInstagram(browser,url):\n",
    "    browser.get(url)\n",
    "    datetime = browser.find_element_by_class_name('_1o9PC.Nzb55').get_attribute('title')\n",
    "    href=browser.find_elements_by_class_name('C4VMK')\n",
    "    #포스트 내용(글, 태그)\n",
    "    total_hash_text=[]    \n",
    "    for i in range(0, len(href)):\n",
    "        hash_text= href[i].find_element_by_css_selector('span').text\n",
    "        total_hash_text.append(hash_text)\n",
    "    tags = re.findall(char, char2.sub(' ',str(total_hash_text)))\n",
    "    user_name = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/article/header/div[2]/div[1]/div[1]/h2/a').text\n",
    "    like_count = int(browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/article/div[2]/section[2]/div/div/button/span').text)\n",
    "    location = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/article/header/div[2]/div[2]/div[2]/a').text\n",
    "    loc_url = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/article/header/div[2]/div[2]/div[2]/a').get_attribute('href')\n",
    "    return datetime, user_name, like_count, tags, location, url, loc_url\n",
    "\n",
    "#4단계 : 크롤링 시행\n",
    "browser = webdriver.Chrome(driver_dir)\n",
    "insta_df=pd.DataFrame(columns = {'Datetime', 'User_Name', 'Like_Count', 'Tags', 'Location','URL', 'Location_URL'})\n",
    "\n",
    "with open('url_part' + str(k) + '.txt', 'r') as f:\n",
    "    urls = f.readlines()\n",
    "for url in urls:\n",
    "    try:\n",
    "        datetime, user_name, like_count, tags, location, url, loc_url = IdHashTagFromInstagram(browser, url.strip('\\n'))\n",
    "        insta_df = insta_df.append({'Datetime': datetime, 'User_Name':user_name, 'Like_Count':like_count,'Tags': tags, 'Location' : location, 'URL':url,'Location_URL' : loc_url}, ignore_index = True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 후 네 개의 데이터 합치기\n",
    "insta_df_part1 = pd.read_csv('testtesttest1.csv', index_col=0, encoding='UTF-8')\n",
    "insta_df_part2 = pd.read_csv('testtesttest2.csv', index_col=0, encoding='UTF-8')\n",
    "insta_df_part3 = pd.read_csv('testtesttest3.csv', index_col=0, encoding='UTF-8')\n",
    "insta_df_part4 = pd.read_csv('testtesttest4.csv', index_col=0, encoding='UTF-8')\n",
    "insta_df_parts = pd.concat([insta_df_part1,insta_df_part2,insta_df_part3,insta_df_part4], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 크롤링 결과 수집된 데이터를 csv로 저장\n",
    "euc-kr로 저장하면 인코딩 문제로 오류나서 utf-8로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_df_parts.to_csv('rawdata_final.csv',mode='w', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 크롤링 완료 후 데이터가 잘 수집되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3159"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insta_df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 전처리 전의 데이터 구조\n",
    "* 샘플수 3159개\n",
    "* 수집 항목 : 작성날짜, 해시태그, 좋아요 수, 위치, 사용자 아이디, 지도url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_URL</th>\n",
       "      <th>Tags</th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>URL</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/explore/locations/37...</td>\n",
       "      <td>['#고소함', '#흑임자', '#치즈케이크', '#할매입맛', '#크리스마스', ...</td>\n",
       "      <td>gosop_gosop</td>\n",
       "      <td>정자동 카페거리</td>\n",
       "      <td>37</td>\n",
       "      <td>https://www.instagram.com/p/B6ZmDGPnAsk/</td>\n",
       "      <td>2019년 12월 23일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/explore/locations/10...</td>\n",
       "      <td>['#달콤수다', '#데이트', '#이쁜그녀들', '#아메리카노', '#레드벨벳케이...</td>\n",
       "      <td>sunapingu</td>\n",
       "      <td>할리스커피(Hollys Coffee)</td>\n",
       "      <td>134</td>\n",
       "      <td>https://www.instagram.com/p/B6H-1k4ldab/</td>\n",
       "      <td>2019년 12월 16일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/explore/locations/15...</td>\n",
       "      <td>['#딸기와플', '#딸기', '#유달리', '#안산유달리', '#유달리안산점', ...</td>\n",
       "      <td>udally_ansan</td>\n",
       "      <td>안산 유달리</td>\n",
       "      <td>29</td>\n",
       "      <td>https://www.instagram.com/p/B6UU24bFo8Q/</td>\n",
       "      <td>2019년 12월 21일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/explore/locations/18...</td>\n",
       "      <td>['#카누', '#윈터블렌드', '#한스오븐', '#마카롱', '#대전마카롱', '...</td>\n",
       "      <td>hans_oven</td>\n",
       "      <td>한스오븐 HAN’s OVEN</td>\n",
       "      <td>23</td>\n",
       "      <td>https://www.instagram.com/p/B6W82JwFMYi/</td>\n",
       "      <td>2019년 12월 22일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/explore/locations/17...</td>\n",
       "      <td>['#한남동카페', '#한남동', '#오지힐']</td>\n",
       "      <td>mocha_jun</td>\n",
       "      <td>오지힐 한남</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.instagram.com/p/B6DOfa8nNsA/</td>\n",
       "      <td>2019년 12월 14일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.instagram.com/explore/locations/43...</td>\n",
       "      <td>[]</td>\n",
       "      <td>cafe_sonane</td>\n",
       "      <td>소나네</td>\n",
       "      <td>49</td>\n",
       "      <td>https://www.instagram.com/p/B6Cz7DvDuXw/</td>\n",
       "      <td>2019년 12월 14일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.instagram.com/explore/locations/13...</td>\n",
       "      <td>[]</td>\n",
       "      <td>cafe.iam.autumn</td>\n",
       "      <td>I Am Autumn</td>\n",
       "      <td>96</td>\n",
       "      <td>https://www.instagram.com/p/B6m2YMvJsck/</td>\n",
       "      <td>2019년 12월 28일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.instagram.com/explore/locations/10...</td>\n",
       "      <td>['#버터힐', '#빠다힐', '#Butterhill', '#버티힐', '#치즈케이...</td>\n",
       "      <td>butter.hill</td>\n",
       "      <td>버터힐</td>\n",
       "      <td>44</td>\n",
       "      <td>https://www.instagram.com/p/B6UQ-7AJ2Kv/</td>\n",
       "      <td>2019년 12월 21일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.instagram.com/explore/locations/44...</td>\n",
       "      <td>['#데일리', '#아이폰11프로맥스', '#카페스타그램', '#인천카페', '#구...</td>\n",
       "      <td>ssu1215</td>\n",
       "      <td>휘게-HyggeCafe</td>\n",
       "      <td>71</td>\n",
       "      <td>https://www.instagram.com/p/B6K5c4lFosw/</td>\n",
       "      <td>2019년 12월 17일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.instagram.com/explore/locations/37...</td>\n",
       "      <td>['#제주카페스르륵', '#오션뷰카페', '#카페', '#바닐라라떼', '#치즈케이...</td>\n",
       "      <td>js_0421.th</td>\n",
       "      <td>제주카페 스르륵</td>\n",
       "      <td>17</td>\n",
       "      <td>https://www.instagram.com/p/B6kj8B_hzsL/</td>\n",
       "      <td>2019년 12월 27일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Location_URL  \\\n",
       "0  https://www.instagram.com/explore/locations/37...   \n",
       "1  https://www.instagram.com/explore/locations/10...   \n",
       "2  https://www.instagram.com/explore/locations/15...   \n",
       "3  https://www.instagram.com/explore/locations/18...   \n",
       "4  https://www.instagram.com/explore/locations/17...   \n",
       "5  https://www.instagram.com/explore/locations/43...   \n",
       "6  https://www.instagram.com/explore/locations/13...   \n",
       "7  https://www.instagram.com/explore/locations/10...   \n",
       "8  https://www.instagram.com/explore/locations/44...   \n",
       "9  https://www.instagram.com/explore/locations/37...   \n",
       "\n",
       "                                                Tags        User_Name  \\\n",
       "0  ['#고소함', '#흑임자', '#치즈케이크', '#할매입맛', '#크리스마스', ...      gosop_gosop   \n",
       "1  ['#달콤수다', '#데이트', '#이쁜그녀들', '#아메리카노', '#레드벨벳케이...        sunapingu   \n",
       "2  ['#딸기와플', '#딸기', '#유달리', '#안산유달리', '#유달리안산점', ...     udally_ansan   \n",
       "3  ['#카누', '#윈터블렌드', '#한스오븐', '#마카롱', '#대전마카롱', '...        hans_oven   \n",
       "4                         ['#한남동카페', '#한남동', '#오지힐']        mocha_jun   \n",
       "5                                                 []      cafe_sonane   \n",
       "6                                                 []  cafe.iam.autumn   \n",
       "7  ['#버터힐', '#빠다힐', '#Butterhill', '#버티힐', '#치즈케이...      butter.hill   \n",
       "8  ['#데일리', '#아이폰11프로맥스', '#카페스타그램', '#인천카페', '#구...          ssu1215   \n",
       "9  ['#제주카페스르륵', '#오션뷰카페', '#카페', '#바닐라라떼', '#치즈케이...       js_0421.th   \n",
       "\n",
       "               Location  Like_Count                                       URL  \\\n",
       "0              정자동 카페거리          37  https://www.instagram.com/p/B6ZmDGPnAsk/   \n",
       "1  할리스커피(Hollys Coffee)         134  https://www.instagram.com/p/B6H-1k4ldab/   \n",
       "2                안산 유달리          29  https://www.instagram.com/p/B6UU24bFo8Q/   \n",
       "3       한스오븐 HAN’s OVEN          23  https://www.instagram.com/p/B6W82JwFMYi/   \n",
       "4                오지힐 한남          12  https://www.instagram.com/p/B6DOfa8nNsA/   \n",
       "5                   소나네          49  https://www.instagram.com/p/B6Cz7DvDuXw/   \n",
       "6           I Am Autumn          96  https://www.instagram.com/p/B6m2YMvJsck/   \n",
       "7                   버터힐          44  https://www.instagram.com/p/B6UQ-7AJ2Kv/   \n",
       "8          휘게-HyggeCafe          71  https://www.instagram.com/p/B6K5c4lFosw/   \n",
       "9              제주카페 스르륵          17  https://www.instagram.com/p/B6kj8B_hzsL/   \n",
       "\n",
       "        Datetime  \n",
       "0  2019년 12월 23일  \n",
       "1  2019년 12월 16일  \n",
       "2  2019년 12월 21일  \n",
       "3  2019년 12월 22일  \n",
       "4  2019년 12월 14일  \n",
       "5  2019년 12월 14일  \n",
       "6  2019년 12월 28일  \n",
       "7  2019년 12월 21일  \n",
       "8  2019년 12월 17일  \n",
       "9  2019년 12월 27일  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta_df_final[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 지도 API를 이용하여 위치정보 텍스트를 위도, 경도로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location 데이터를 리스트로 가져오기\n",
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "insta_df_final.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "addr_list = []\n",
    "for k in insta_df_final['Location']:\n",
    "    addr_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정자동 카페거리',\n",
       " '할리스커피(Hollys Coffee)',\n",
       " '안산 유달리',\n",
       " '한스오븐 HAN’s OVEN',\n",
       " '오지힐 한남',\n",
       " '소나네',\n",
       " 'I Am Autumn',\n",
       " '버터힐',\n",
       " '휘게-HyggeCafe',\n",
       " '제주카페 스르륵',\n",
       " 'Anoseestudio',\n",
       " '빌리엔젤강남',\n",
       " '고고케이크',\n",
       " '스타벅스 스타필드 위례 1f R점',\n",
       " '레몬드 Lemoned',\n",
       " 'Busan, South Korea',\n",
       " 'Seoul, South Korea',\n",
       " 'Jeju',\n",
       " '동부이촌동',\n",
       " '버터힐']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주소로 좌표 얻기\n",
    "import json\n",
    "import requests\n",
    "MY_APP_KEY = '3123c75b5738c8b04d18ea0521ee9f02'\n",
    "xyList = []\n",
    "\n",
    "for addr in addr_list:\n",
    "    url = 'https://dapi.kakao.com/v2/local/search/address.json?query='+addr\n",
    "    headers = {\"Authorization\": 'KakaoAK ' + MY_APP_KEY}\n",
    "\n",
    "\n",
    "    result = json.loads(str(requests.get(url, headers=headers).text))\n",
    "    address = result['documents']\n",
    "    for adr in address:\n",
    "        x = float(adr['x'])\n",
    "        y = float(adr['y'])\n",
    "        tempDic = {\"x\" : x, \"y\":y}\n",
    "        xyList.append(tempDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 126.97331680470317, 'y': 37.521396531912345},\n",
       " {'x': 127.01267486884748, 'y': 37.28409156410657},\n",
       " {'x': 127.01267486884748, 'y': 37.28409156410657},\n",
       " {'x': 127.25181585514171, 'y': 36.48510961987026},\n",
       " {'x': 127.28919533809494, 'y': 36.480068515997694},\n",
       " {'x': 127.25181585514171, 'y': 36.48510961987026},\n",
       " {'x': 126.72100102482857, 'y': 35.027552857964984},\n",
       " {'x': 129.3470540257457, 'y': 35.564738246904575},\n",
       " {'x': 126.72100102482857, 'y': 35.027552857964984},\n",
       " {'x': 129.3470540257457, 'y': 35.564738246904575}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyList[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 분석방법, 흐름소개\n",
    "* 분석방법 : 크롤링, 빈도분석, 지도 API를 이용하여 위치정보 텍스트를 위도, 경도로 변환\n",
    "* 흐름 소개 (동영상, 각종코드 넣기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시연을 위해 크롤링으로 얻은 raw data 로드\n",
    "(데이터 구조를 보여준다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insta_df_final = pd.read_csv('rawdata_final.csv', index_col=0, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빈도분석\n",
    "수집한 데이터가 좋아요 수, 위도, 경도를 제외하고는 모두 범주형 데이터이다.  \n",
    "해시태그에 대해 빈도분석을 진행해보았다.  \n",
    "--> 대체로 유의미한 데이터로 보인다. 키워드와 관련된 단어를 분석하는 워드클라우드를 적용해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#치즈케이크', 871),\n",
       " ('#카페', 172),\n",
       " ('#일상', 137),\n",
       " ('#디저트', 120),\n",
       " ('#카페투어', 107),\n",
       " ('#크리스마스', 105),\n",
       " ('#cafe', 94),\n",
       " ('#카페스타그램', 84),\n",
       " ('#cheesecake', 84),\n",
       " ('#케이크', 83),\n",
       " ('#디저트카페', 80),\n",
       " ('#커피', 77),\n",
       " ('#coffee', 77),\n",
       " ('#마카롱', 76),\n",
       " ('#먹스타그램', 75),\n",
       " ('#데일리', 75),\n",
       " ('#좋아요', 63),\n",
       " ('#daily', 54),\n",
       " ('#딸기케이크', 51),\n",
       " ('#dessert', 49),\n",
       " ('#맛집', 49),\n",
       " ('#맛스타그램', 49),\n",
       " ('#아메리카노', 48),\n",
       " ('#스콘', 46),\n",
       " ('#딸기', 46),\n",
       " ('#맞팔', 46),\n",
       " ('#디저트맛집', 46),\n",
       " ('#부산카페', 44),\n",
       " ('#크리스마스케이크', 43),\n",
       " ('#소통', 42),\n",
       " ('#티라미수', 40),\n",
       " ('#마카롱맛집', 39),\n",
       " ('#cake', 39),\n",
       " ('#예쁜카페', 37),\n",
       " ('#브라우니', 34),\n",
       " ('#메리크리스마스', 33),\n",
       " ('#먹방', 33),\n",
       " ('#팔로우', 31),\n",
       " ('#초코케이크', 31),\n",
       " ('#마들렌', 30),\n",
       " ('#제리치즈케이크', 29),\n",
       " ('#선물', 29),\n",
       " ('#macarons', 29),\n",
       " ('#좋반', 29),\n",
       " ('#밀크티', 28),\n",
       " ('#커피맛집', 28),\n",
       " ('#크리스마스이브', 28),\n",
       " ('#세종시마카롱', 28),\n",
       " ('#새롬동카페', 28),\n",
       " ('#신상카페', 27)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "insta_tags = []\n",
    "for tags in insta_df_final['Tags']:\n",
    "    tags = tags.strip('[').strip(']').replace(\"'\", \"\")\n",
    "    tag_list = tags.split(', ')\n",
    "    while '' in tag_list:\n",
    "        tag_list.remove('')\n",
    "    insta_tags.extend(tag_list)\n",
    "    \n",
    "c = Counter(insta_tags)\n",
    "    \n",
    "c.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 시각화 도구와 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Folium 라이브러리를 이용하여 여러 방법으로 데이터를 시각화한다.  \n",
    "이유: 지도 데이터에 위치정보를 시각화 하여 한눈에 어느지역에 분포되어 있는지 알아보기 쉽다\n",
    "* #치즈케이크 해시태그와 연관된 단어를 워드클라우드로 시각화한다.  \n",
    "치즈케이크와 함께 언급량이 많은 단어를 분석함으로써 치즈케이크를 찾는 사람들의 관심사를 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 분석 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Folium 을 이용한 지도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(addr_list))\n",
    "print(len(xyList))\n",
    "print(len(guList))\n",
    "\n",
    "cheesecake_map = folium.Map(location=[37.514322572335935, 127.06283102249932],zoom_start=10)\n",
    "for i in xyList:\n",
    "    x = i['x']\n",
    "    y = i['y']\n",
    "    folium.Marker([y, x],icon=folium.Icon(color='orange')).add_to(cheesecake_map)\n",
    "\n",
    "geo_path = 'skorea_municipalities_geo_simple.json'\n",
    "geo_str = json.load(open(geo_path, encoding='utf-8'))\n",
    "gu_df = pd.DataFrame(columns = ['Gu', 'Frequency'])\n",
    "gu_df['Gu'] = [x['id'] for x in geo_str['features']]\n",
    "\n",
    "for k in range(len(gu_df)):\n",
    "    count = guList.count(gu_df['Gu'][k])\n",
    "    gu_df['Frequency'][k] = count\n",
    "\n",
    "gu_df['Frequency'] = gu_df['Frequency'].astype(int)\n",
    "gu_df['Gu'] = gu_df['Gu'].astype(str)\n",
    "gu_df.set_index('Gu', inplace = True)\n",
    "\n",
    "\n",
    "map.choropleth(geo_data = geo_str,\n",
    "               data = gu_df.Frequency,\n",
    "               columns = [gu_df.index, gu_df.Frequency],\n",
    "               fill_color = 'YlGnBu',\n",
    "               key_on = 'feature.id') #PuRd, YlGnBu\n",
    "\n",
    "for i in xyList:\n",
    "    x = i['x']\n",
    "    y = i['y']\n",
    "    folium.Marker([y, x],icon=folium.Icon(color='orange')).add_to(map)\n",
    "\n",
    "map.save('cheesecake_seoul.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 워드클라우드 (미완성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "insta_tags = []\n",
    "for tags in insta_df_final['Tags']:\n",
    "    tags = tags.strip('[').strip(']').replace(\"'\", \"\")\n",
    "    tag_list = tags.split(', ')\n",
    "    while '' in tag_list:\n",
    "        tag_list.remove('')\n",
    "    insta_tags.extend(tag_list)\n",
    "    \n",
    "c = Counter(insta_tags)\n",
    "    \n",
    "c.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 보완할 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 프로젝트 느낀점"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
